-- Create the scraping_queue table to manage scraping jobs
CREATE TABLE public.scraping_queue (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    website_id BIGINT REFERENCES public.websites(id) ON DELETE SET NULL,
    url_to_scrape TEXT NOT NULL UNIQUE,
    status TEXT NOT NULL DEFAULT 'pending' CHECK (status IN ('pending', 'processing', 'completed', 'failed')),
    attempts INT NOT NULL DEFAULT 0,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    last_processed_at TIMESTAMPTZ,
    error_log TEXT
);

-- Add comments to the columns
COMMENT ON TABLE public.scraping_queue IS 'A queue of URLs to be scraped by Firecrawl.';
COMMENT ON COLUMN public.scraping_queue.status IS 'The current status of the scraping job: pending, processing, completed, or failed.';
COMMENT ON COLUMN public.scraping_queue.attempts IS 'The number of times a scraping job has been attempted.';

-- Create indexes for faster queries
CREATE INDEX idx_scraping_queue_status ON public.scraping_queue(status);
CREATE INDEX idx_scraping_queue_created_at ON public.scraping_queue(created_at);

-- Enable Row Level Security
ALTER TABLE public.scraping_queue ENABLE ROW LEVEL SECURITY;

-- Create policies for access
CREATE POLICY "Allow full access to service_role"
ON public.scraping_queue
FOR ALL
USING (auth.role() = 'service_role')
WITH CHECK (auth.role() = 'service_role');

CREATE POLICY "Allow authenticated read access"
ON public.scraping_queue
FOR SELECT
USING (auth.role() = 'authenticated');
